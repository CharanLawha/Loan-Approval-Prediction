# ğŸ¦ Loan Approval Prediction â€” End-to-End  

This notebook is a complete starter for **Loan Approval Prediction** on a Kaggle-style dataset.  
It demonstrates how to build, evaluate, and compare machine learning models in an end-to-end workflow.  

---

## ğŸ“Œ Project Overview  
The goal is to predict whether a loan application will be **Approved (Y)** or **Rejected (N)** based on applicant details such as income, credit history, and property area.  

This project covers:  
- âœ… Data loading & quick checks  
- âœ… Preprocessing (missing values, categorical encoding, train/test split)  
- âœ… Handling imbalanced data (class weights, SMOTE)  
- âœ… Models: **Logistic Regression** vs **Decision Tree**  
- âœ… Metrics: Precision, Recall, F1-score, ROC-AUC, Confusion Matrix  
- âœ… Threshold tuning for Logistic Regression using **Precision-Recall Curve**  

---

## ğŸ“‚ Project Structure  
â”œâ”€â”€ Loan_Approval_Prediction.ipynb # Main training & evaluation notebook
â”œâ”€â”€ sample_loan_approval.csv # Sample dataset
â”œâ”€â”€ README.md # Project documentation



---

## ğŸ“Š Dataset  
Each record contains the following fields:  

- **Loan_ID** â€“ Unique Loan Identifier  
- **Gender** â€“ Male / Female  
- **Married** â€“ Yes / No  
- **Dependents** â€“ Number of dependents  
- **Education** â€“ Graduate / Not Graduate  
- **Self_Employed** â€“ Yes / No  
- **ApplicantIncome** â€“ Income of applicant  
- **CoapplicantIncome** â€“ Income of co-applicant  
- **LoanAmount** â€“ Loan amount (in thousands)  
- **Loan_Amount_Term** â€“ Loan repayment term (in days)  
- **Credit_History** â€“ Credit history meets guidelines (1/0)  
- **Property_Area** â€“ Urban / Semiurban / Rural  
- **Loan_Status** â€“ Target variable (Y = Approved, N = Rejected)  

---

## âš™ï¸ Workflow  

### 1. Data Preprocessing  
- Handle missing values  
- Encode categorical variables  
- Scale numerical features  
- Train/Test split  

### 2. Handling Imbalanced Data  
- **Option 1:** `class_weight="balanced"` for Logistic Regression  
- **Option 2:** **SMOTE** oversampling for minority class  

### 3. Model Training  
- **Logistic Regression** (baseline & threshold tuning)  
- **Decision Tree** (rule-based learning)  

### 4. Model Evaluation  
We use multiple metrics for fair comparison:  
- Confusion Matrix  
- Precision, Recall, F1-score  
- ROC-AUC score  
- Precision-Recall Curve for threshold tuning  

---

## ğŸ“ˆ Results  

### Confusion Matrix Example  
|                | Predicted Approved (Y) | Predicted Rejected (N) |
|----------------|-------------------------|-------------------------|
| **Actual Approved (Y)** | True Positive (TP) | False Negative (FN) |
| **Actual Rejected (N)** | False Positive (FP) | True Negative (TN) |

- **Logistic Regression**: Better at generalization, stable with threshold tuning.  
- **Decision Tree**: Captures complex rules but may overfit.  

---
